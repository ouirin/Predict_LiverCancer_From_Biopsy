{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd59734-9ecf-4a70-89e8-52708025f12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import ntpath\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480739a3-987b-4143-8864-1a31f4cbf793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "src_path = \"G:/LiverCancer/nucleus/image/\"\n",
    "\n",
    "nucleus_samples = [file for fold_1 in os.listdir(src_path)\n",
    "                        for fold_2 in os.listdir(os.path.join(src_path, fold_1))\n",
    "                        for file in glob.glob(os.path.join(src_path, fold_1, fold_2, \"*.jpg\"))]\n",
    "\n",
    "samples_grade_0, samples_grade_1, samples_grade_2, samples_grade_3, samples_grade_4 = [], [], [], [], []\n",
    "\n",
    "for index, nucleus_sample in enumerate(nucleus_samples):\n",
    "\n",
    "    if \"grade0\" in nucleus_sample: samples_grade_0 += [ [nucleus_sample, 0] ]\n",
    "    if \"grade1\" in nucleus_sample: samples_grade_1 += [ [nucleus_sample, 1] ]\n",
    "    if \"grade2\" in nucleus_sample: samples_grade_2 += [ [nucleus_sample, 2] ]\n",
    "    if \"grade3\" in nucleus_sample: samples_grade_3 += [ [nucleus_sample, 3] ]\n",
    "    if \"grade4\" in nucleus_sample: samples_grade_4 += [ [nucleus_sample, 4] ]\n",
    "\n",
    "# 加载模型\n",
    "model = get_net(load_weight_path = \"G:/LiverCancer/model/model_liver_CNN_Cluster.hd5\")\n",
    "\n",
    "feature_extractor = Model(inputs=model.input, outputs=model.get_layer('final_features_64').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc2dbed-ce4c-43a6-98f9-f249787e0881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取特征\n",
    "features = []\n",
    "\n",
    "for index, record in enumerate(samples_grade_4):\n",
    "    \n",
    "    sample_image = cv2.imread(record[0])\n",
    "    sample_image = (sample_image - np.average(sample_image)) / np.std(sample_image)\n",
    "    sample_image = sample_image.reshape(1, sample_image.shape[0], sample_image.shape[1], 3)\n",
    "    \n",
    "    norm_feat = feature_extractor.predict(sample_image)[0]\n",
    "    features += [norm_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1949a346-a6f2-4146-a87d-158705ce889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 聚类\n",
    "features = np.array(features)[:,1].tolist()\n",
    "kmeans = KMeans(n_clusters=3, random_state=0).fit(features)\n",
    "\n",
    "# 降维可视化\n",
    "pca = PCA(n_components=2)\n",
    "pca_res = pca.fit_transform(features) \n",
    "plt.scatter(pca_res[:, 0], pca_res[:, 1], c=kmeans.labels_)\n",
    "plt.show()\n",
    "\n",
    "# 计算样本到重心的距离\n",
    "centre_points = np.mean(kmeans.cluster_centers_, axis=0)\n",
    "\n",
    "distances = np.sum(np.abs(features - centre_points), axis=1).tolist()\n",
    "\n",
    "# 根据距离排序，选距离较近90%\n",
    "distances_sorted = np.array(distances).argsort()\n",
    "\n",
    "count = int(len(features)*0.9)\n",
    "\n",
    "selected = distances_sorted[0:count]\n",
    "\n",
    "# 保存数据\n",
    "for index, record in enumerate(samples_grade_4):\n",
    "    \n",
    "    sample_path = record[0]\n",
    "    \n",
    "    if index in selected:\n",
    "        shutil.copy(sample_path, \"G:/LiverCancer/nucleus/image_filtered/grade4/1/\"+ntpath.basename(sample_path))\n",
    "    else:\n",
    "        shutil.copy(sample_path, \"G:/LiverCancer/nucleus/image_filtered/grade4/0/\"+ntpath.basename(sample_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e5d8d2-ffab-421f-952d-60cd276fd738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1482cc-9e3f-4e99-b18f-8b2b71aae03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.advanced_activations import ReLU\n",
    "from keras.metrics import categorical_accuracy, categorical_crossentropy\n",
    "from keras.layers import Input,AveragePooling2D,Convolution2D,BatchNormalization,MaxPooling2D,Concatenate,GlobalMaxPooling2D,Dense\n",
    "\n",
    "def get_net(input_shape=(128, 128, 3), load_weight_path=None) -> Model:\n",
    "    \n",
    "    inputs = Input(shape=input_shape, name=\"input\")\n",
    "    x = inputs\n",
    "    \n",
    "    x_ident_1 = x\n",
    "    x_ident_1 = AveragePooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid')(x_ident_1)\n",
    "    # 1st layer group\n",
    "    x = Convolution2D(16, 3, 3, activation=None, border_mode='same', name='conv1a', subsample=(1, 1))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Convolution2D(16, 3, 3, activation=None, border_mode='same', name='conv1b', subsample=(1, 1))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid', name='pool1')(x)\n",
    "    x = Concatenate(axis=3)([x,x_ident_1])\n",
    "    \n",
    "    x_ident_1 = AveragePooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid')(x_ident_1)\n",
    "    x_ident_2 = AveragePooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid')(x)\n",
    "    # 2nd layer group\n",
    "    x = Convolution2D(32, 3, 3, activation=None, border_mode='same', name='conv2a', subsample=(1, 1))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Convolution2D(32, 3, 3, activation=None, border_mode='same', name='conv2b', subsample=(1, 1))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid', name='pool2')(x)\n",
    "    x = Concatenate(axis=3)([x,x_ident_1,x_ident_2])\n",
    "    \n",
    "    x_ident_1 = AveragePooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid')(x_ident_1)\n",
    "    x_ident_2 = AveragePooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid')(x_ident_2)\n",
    "    x_ident_3 = AveragePooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid')(x)\n",
    "    # 3rd layer group\n",
    "    x = Convolution2D(64, 3, 3, activation=None, border_mode='same', name='conv3a', subsample=(1, 1))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Convolution2D(64, 3, 3, activation=None, border_mode='same', name='conv3b', subsample=(1, 1))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid', name='pool3')(x)\n",
    "    x = Concatenate(axis=3)([x,x_ident_1,x_ident_2,x_ident_3])\n",
    "     \n",
    "    x_ident_1 = AveragePooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid')(x_ident_1)\n",
    "    x_ident_2 = AveragePooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid')(x_ident_2)\n",
    "    x_ident_3 = AveragePooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid')(x_ident_3)\n",
    "    x_ident_4 = AveragePooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid')(x)\n",
    "    # 4th layer group\n",
    "    x = Convolution2D(128, 3, 3, activation=None, border_mode='same', name='conv4a', subsample=(1, 1),)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Convolution2D(128, 3, 3, activation=None, border_mode='same', name='conv4b', subsample=(1, 1),)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid', name='pool4')(x)\n",
    "    x = Concatenate(axis=3)([x,x_ident_1,x_ident_2,x_ident_3,x_ident_4])\n",
    "    \n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    x = BatchNormalization(name=\"final_features\")(x)\n",
    "        \n",
    "    x = Dense(64, activation='relu', name='final_features_64')(x)\n",
    "    out_class = Dense(5, activation='softmax', name='out_class')(x)\n",
    "\n",
    "    model = Model(input=inputs, output=out_class)\n",
    "    \n",
    "    if load_weight_path is not None: model.load_weights(load_weight_path, by_name=False)\n",
    "\n",
    "    optimizer = SGD(lr=0.001, momentum=0.9, nesterov=True)\n",
    "    loss = {\"out_class\": \"categorical_crossentropy\"}\n",
    "    metrics={\"out_class\": [categorical_accuracy, categorical_crossentropy]}\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    model.summary(line_length=140)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6545055e-c785-4667-a721-7b23578d64ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7d3980-83ae-41a8-a72e-d8a43941d0b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890853e5-8a54-4d8b-b720-788c143dbfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import ntpath\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from imblearn import over_sampling\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils \n",
    "from keras.layers.advanced_activations import ReLU\n",
    "from keras.callbacks import LearningRateScheduler,ModelCheckpoint\n",
    "from keras.metrics import categorical_accuracy, categorical_crossentropy\n",
    "from keras.layers import Input,AveragePooling2D,Convolution2D,BatchNormalization,MaxPooling2D,Concatenate,GlobalMaxPooling2D,Dense,concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d22218-86f7-4656-82b1-17ae2deaf78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "trainset, testset = load_data()\n",
    "\n",
    "train_gen = data_generator(batch_size, trainset, need_augment=True)\n",
    "\n",
    "test_gen = data_generator(batch_size, testset, need_augment=False)\n",
    "\n",
    "learnrate_scheduler = LearningRateScheduler(step_decay)\n",
    "\n",
    "model = get_net(load_weight_path=None)\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"G:/LiverCancer/model/\" + \"{epoch:02d}-{val_loss:.4f}.hd5\", monitor='val_loss', period=1)\n",
    "\n",
    "model.fit_generator(train_gen, int(len(trainset)/batch_size), 10, validation_data=test_gen, nb_val_samples=int(len(testset)/batch_size), callbacks=[checkpoint, learnrate_scheduler])\n",
    "\n",
    "model.save(\"G:/LiverCancer/model/the_end.hd5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94b7bb0-0420-45b3-8b8e-ed7e2387752a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "\n",
    "    split_rule = 1\n",
    "    \n",
    "    src_path = \"G:/LiverCancer/resources/split_rule/\" + str(split_rule) +\"/\"\n",
    "\n",
    "    train_biopsy_names = pd.read_csv(src_path + \"train.csv\")[\"file_path\"].apply(ntpath.basename).tolist()\n",
    "    test_biopsy_names = pd.read_csv(src_path + \"holdout.csv\")[\"file_path\"].apply(ntpath.basename).tolist()\n",
    "    \n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    src_path = \"G:/LiverCancer/masked_biopsy_resized/\"\n",
    "\n",
    "    biopsy_masks = [file_path for fold in os.listdir(src_path) for file_path in glob.glob(os.path.join(src_path, fold, \"*.jpg\"))]\n",
    "\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    src_path = \"G:/LiverCancer/nucleus/image_filtered/\"\n",
    "    \n",
    "    nucleus_samples = [file for fold in os.listdir(src_path) for file in glob.glob(os.path.join(src_path, fold, '1', \"*.jpg\"))]\n",
    "    \n",
    "    train_nucleus_samples = []\n",
    "\n",
    "    for index, nucleus_sample in enumerate(nucleus_samples):\n",
    "\n",
    "        temp = ntpath.basename(nucleus_sample).split(\"_\")\n",
    "        if (temp[0] + temp[1]) == \"grade0\": nucleus_sample_from = \"ImageN\" + \".\" + temp[2] + \".jpg\"\n",
    "        if (temp[0] + temp[1]) == \"grade1\": nucleus_sample_from = \"Image1\" + \"-\" + temp[2] + \".jpg\"\n",
    "        if (temp[0] + temp[1]) == \"grade2\": nucleus_sample_from = \"Image2\" + \"-\" + temp[2] + \".jpg\"\n",
    "        if (temp[0] + temp[1]) == \"grade3\": nucleus_sample_from = \"Image3\" + \"-\" + temp[2] + \".jpg\"\n",
    "        if (temp[0] + temp[1]) == \"grade4\": nucleus_sample_from = \"Image4\" + \"-\" + temp[2] + \".jpg\"\n",
    "\n",
    "        if nucleus_sample_from in train_biopsy_names: train_nucleus_samples += [nucleus_sample]\n",
    "\n",
    "    src_path = \"G:/LiverCancer/nucleus/image/\"\n",
    "\n",
    "    nucleus_samples = [file for fold_1 in os.listdir(src_path)\n",
    "                            for fold_2 in os.listdir(os.path.join(src_path, fold_1))\n",
    "                            for file in glob.glob(os.path.join(src_path, fold_1, fold_2, \"*.jpg\"))]\n",
    "\n",
    "    test_nucleus_samples = [s for s in nucleus_samples if (s.split(\".jpg\")[0][-9:]+\".jpg\") in test_biopsy_names]\n",
    "\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    train_samples, test_samples = [], []\n",
    "\n",
    "    for index, train_nucleus_sample in enumerate(train_nucleus_samples):\n",
    "        \n",
    "        temp = ntpath.basename(train_nucleus_sample).split(\"_\")\n",
    "        if temp[0]+temp[1] == \"grade0\": biopsy_mask_from = \"ImageN.\"+temp[2]+\".jpg\"\n",
    "        if temp[0]+temp[1] == \"grade1\": biopsy_mask_from = \"Image1-\"+temp[2]+\".jpg\"\n",
    "        if temp[0]+temp[1] == \"grade2\": biopsy_mask_from = \"Image2-\"+temp[2]+\".jpg\"\n",
    "        if temp[0]+temp[1] == \"grade3\": biopsy_mask_from = \"Image3-\"+temp[2]+\".jpg\"\n",
    "        if temp[0]+temp[1] == \"grade4\": biopsy_mask_from = \"Image4-\"+temp[2]+\".jpg\"\n",
    "            \n",
    "        for biopsy_mask in biopsy_masks:\n",
    "            \n",
    "            if biopsy_mask_from in biopsy_mask: biopsy_mask_from = biopsy_mask\n",
    "                \n",
    "        if \"grade0\" in train_nucleus_sample: train_samples += [ [train_nucleus_sample, biopsy_mask_from, 0] ]\n",
    "        if \"grade1\" in train_nucleus_sample: train_samples += [ [train_nucleus_sample, biopsy_mask_from, 1] ]\n",
    "        if \"grade2\" in train_nucleus_sample: train_samples += [ [train_nucleus_sample, biopsy_mask_from, 2] ]\n",
    "        if \"grade3\" in train_nucleus_sample: train_samples += [ [train_nucleus_sample, biopsy_mask_from, 3] ]\n",
    "        if \"grade4\" in train_nucleus_sample: train_samples += [ [train_nucleus_sample, biopsy_mask_from, 4] ]\n",
    "\n",
    "    for index, test_nucleus_sample in enumerate(test_nucleus_samples):\n",
    "\n",
    "        temp = ntpath.basename(test_nucleus_sample).split(\"_\")\n",
    "        if temp[0]+temp[1] == \"grade0\": biopsy_mask_from = \"ImageN.\"+temp[2]+\".jpg\"\n",
    "        if temp[0]+temp[1] == \"grade1\": biopsy_mask_from = \"Image1-\"+temp[2]+\".jpg\"\n",
    "        if temp[0]+temp[1] == \"grade2\": biopsy_mask_from = \"Image2-\"+temp[2]+\".jpg\"\n",
    "        if temp[0]+temp[1] == \"grade3\": biopsy_mask_from = \"Image3-\"+temp[2]+\".jpg\"\n",
    "        if temp[0]+temp[1] == \"grade4\": biopsy_mask_from = \"Image4-\"+temp[2]+\".jpg\"\n",
    "            \n",
    "        for biopsy_mask in biopsy_masks:\n",
    "            \n",
    "            if biopsy_mask_from in biopsy_mask: biopsy_mask_from = biopsy_mask\n",
    "\n",
    "        if \"grade0\" in test_nucleus_sample: test_samples += [ [test_nucleus_sample, biopsy_mask_from, 0] ]\n",
    "        if \"grade1\" in test_nucleus_sample: test_samples += [ [test_nucleus_sample, biopsy_mask_from, 1] ]\n",
    "        if \"grade2\" in test_nucleus_sample: test_samples += [ [test_nucleus_sample, biopsy_mask_from, 2] ]\n",
    "        if \"grade3\" in test_nucleus_sample: test_samples += [ [test_nucleus_sample, biopsy_mask_from, 3] ]\n",
    "        if \"grade4\" in test_nucleus_sample: test_samples += [ [test_nucleus_sample, biopsy_mask_from, 4] ]\n",
    "            \n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    train_samples_x = np.array(train_samples)[:,0:2]\n",
    "    train_samples_y = np.array(train_samples)[:,2].reshape(-1,1)\n",
    "\n",
    "    ros = over_sampling.RandomOverSampler(random_state=0)\n",
    "    train_samples_x, train_samples_y = ros.fit_resample(train_samples_x, train_samples_y)\n",
    "   \n",
    "    sns.countplot(train_samples_y)\n",
    "\n",
    "    train_samples = np.hstack((train_samples_x, train_samples_y.reshape(-1,1))).tolist()\n",
    "\n",
    "    random.shuffle(train_samples)\n",
    "    random.shuffle(test_samples)\n",
    "\n",
    "    return train_samples, test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381871e5-954a-4d97-8620-f141d792733c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(batch_size, record_list, need_augment):\n",
    "        \n",
    "    batch_counter, image_list, mask_list, label_list = 0, [], [], []\n",
    "   \n",
    "    if need_augment: random.shuffle(record_list)\n",
    "\n",
    "    #按照batch_size动态生成数据\n",
    "    for index, record in enumerate(record_list):\n",
    "\n",
    "        sample_path = record[0]\n",
    "        mask_path = record[1]\n",
    "        sample_label = record[2]\n",
    "\n",
    "        #转换成多分类标签\n",
    "        sample_label = np_utils.to_categorical(sample_label,5)  \n",
    "\n",
    "        #读取图片、修改尺寸、标准化\n",
    "        sample_image = cv2.imread(sample_path)\n",
    "        sample_image = (sample_image - np.average(sample_image)) / np.std(sample_image)\n",
    "        sample_image = sample_image.reshape(1, sample_image.shape[0], sample_image.shape[1], 3)\n",
    "        \n",
    "        #读取mask、修改尺寸、标准化\n",
    "        mask_image = cv2.imread(mask_path)\n",
    "        indent_x = random.randint(0, 128)\n",
    "        indent_y = random.randint(0, 128)       \n",
    "        mask_image = mask_image[indent_x:indent_x + 128, indent_y:indent_y + 128]\n",
    "        mask_image = (mask_image - np.average(mask_image)) / np.std(mask_image)\n",
    "        mask_image = mask_image.reshape(1, mask_image.shape[0], mask_image.shape[1], 3)\n",
    "        \n",
    "        if need_augment:  \n",
    "            if random.randint(0, 100) > 50: sample_image = np.fliplr(sample_image)\n",
    "            if random.randint(0, 100) > 50: sample_image = np.flipud(sample_image)\n",
    "            if random.randint(0, 100) > 50: sample_image = sample_image[:,::-1]\n",
    "            if random.randint(0, 100) > 50: sample_image = sample_image[::-1, :]\n",
    "                \n",
    "            if random.randint(0, 100) > 50: mask_image = np.fliplr(mask_image)\n",
    "            if random.randint(0, 100) > 50: mask_image = np.flipud(mask_image)\n",
    "            if random.randint(0, 100) > 50: mask_image = mask_image[:,::-1]\n",
    "            if random.randint(0, 100) > 50: mask_image = mask_image[::-1, :]\n",
    "\n",
    "        image_list.append(sample_image); mask_list.append(mask_image); label_list.append(sample_label)\n",
    "        \n",
    "        batch_counter += 1\n",
    "\n",
    "        if batch_counter >= batch_size:\n",
    "            \n",
    "            x_sample = np.vstack(image_list); x_mask = np.vstack(mask_list); y = np.vstack(label_list)\n",
    "            \n",
    "            yield {\"sample_image\":x_sample, \"mask_image\":x_mask}, y\n",
    "            \n",
    "            image_list = []; mask_list = []; label_list = []\n",
    "            \n",
    "            batch_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851d9521-b155-4bac-bf38-695c1f2913d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "    \n",
    "    res = 0.001\n",
    "    \n",
    "    if epoch > 10:\n",
    "        \n",
    "        res = 0.0001\n",
    "        \n",
    "    print(\"learnrate: \", res, \" epoch: \", epoch)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b0885e-6d58-479b-9956-2533658239ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_net(input_shape=(128, 128, 3), load_weight_path=None) -> Model:  \n",
    "    \n",
    "    inputs = Input(shape=input_shape, name=\"sample_image\")\n",
    "    inputs_mask = Input(shape=input_shape, name=\"mask_image\")\n",
    "    x = inputs\n",
    "    x_mask = inputs_mask\n",
    "    \n",
    "    ##################################################################################################################\n",
    "    x_ident_1 = x\n",
    "    x_ident_1 = AveragePooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid')(x_ident_1)\n",
    "    # 1st layer group\n",
    "    x = Convolution2D(16, 3, 3, activation=None, border_mode='same', name='conv1a', subsample=(1, 1))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Convolution2D(16, 3, 3, activation=None, border_mode='same', name='conv1b', subsample=(1, 1))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid', name='pool1')(x)\n",
    "    x = Concatenate(axis=3)([x,x_ident_1])\n",
    "    \n",
    "    x_ident_1 = AveragePooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid')(x_ident_1)\n",
    "    x_ident_2 = AveragePooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid')(x)\n",
    "    # 2nd layer group\n",
    "    x = Convolution2D(32, 3, 3, activation=None, border_mode='same', name='conv2a', subsample=(1, 1))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Convolution2D(32, 3, 3, activation=None, border_mode='same', name='conv2b', subsample=(1, 1))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid', name='pool2')(x)\n",
    "    x = Concatenate(axis=3)([x,x_ident_1,x_ident_2])\n",
    "\n",
    "    x_ident_1 = AveragePooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid')(x_ident_1)\n",
    "    x_ident_2 = AveragePooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid')(x_ident_2)\n",
    "    x_ident_3 = AveragePooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid')(x)\n",
    "    # 3rd layer group\n",
    "    x = Convolution2D(64, 3, 3, activation=None, border_mode='same', name='conv3a', subsample=(1, 1))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Convolution2D(64, 3, 3, activation=None, border_mode='same', name='conv3b', subsample=(1, 1))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid', name='pool3')(x)\n",
    "    x = Concatenate(axis=3)([x,x_ident_1,x_ident_2,x_ident_3])\n",
    "     \n",
    "    x_ident_1 = AveragePooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid')(x_ident_1)\n",
    "    x_ident_2 = AveragePooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid')(x_ident_2)\n",
    "    x_ident_3 = AveragePooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid')(x_ident_3)\n",
    "    x_ident_4 = AveragePooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid')(x)\n",
    "    # 4th layer group\n",
    "    x = Convolution2D(128, 3, 3, activation=None, border_mode='same', name='conv4a', subsample=(1, 1),)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Convolution2D(128, 3, 3, activation=None, border_mode='same', name='conv4b', subsample=(1, 1),)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid', name='pool4')(x)\n",
    "    x = Concatenate(axis=3)([x,x_ident_1,x_ident_2,x_ident_3,x_ident_4])\n",
    "    \n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    x = BatchNormalization(name=\"final_features_344\")(x)\n",
    "    \n",
    "    ##################################################################################################################\n",
    "    x_mask_ident_1 = x_mask\n",
    "    x_mask_ident_1 = AveragePooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid')(x_mask_ident_1)\n",
    "    # 1st layer group\n",
    "    x_mask = Convolution2D(8, 3, 3, activation=None, border_mode='same', name='conv1_mask', subsample=(1, 1))(x_mask)\n",
    "    x_mask = BatchNormalization()(x_mask)\n",
    "    x_mask = ReLU()(x_mask)\n",
    "    x_mask = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid', name='pool1_mask')(x_mask)\n",
    "    x_mask = Concatenate(axis=3)([x_mask,x_mask_ident_1])\n",
    "    \n",
    "    x_mask_ident_1 = AveragePooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid')(x_mask_ident_1)\n",
    "    x_mask_ident_2 = AveragePooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid')(x_mask)\n",
    "    # 2nd layer group\n",
    "    x_mask = Convolution2D(16, 3, 3, activation=None, border_mode='same', name='conv2_mask', subsample=(1, 1))(x_mask)\n",
    "    x_mask = BatchNormalization()(x_mask)\n",
    "    x_mask = ReLU()(x_mask)\n",
    "    x_mask = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid', name='pool2_mask')(x_mask)\n",
    "    x_mask = Concatenate(axis=3)([x_mask,x_mask_ident_1,x_mask_ident_2])\n",
    "\n",
    "    x_mask_ident_1 = AveragePooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid')(x_mask_ident_1)\n",
    "    x_mask_ident_2 = AveragePooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid')(x_mask_ident_2)\n",
    "    x_mask_ident_3 = AveragePooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid')(x_mask)\n",
    "    # 3rd layer group\n",
    "    x_mask = Convolution2D(32, 3, 3, activation=None, border_mode='same', name='conv3_mask', subsample=(1, 1))(x_mask)\n",
    "    x_mask = BatchNormalization()(x_mask)\n",
    "    x_mask = ReLU()(x_mask)\n",
    "    x_mask = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid', name='pool3_mask')(x_mask)\n",
    "    x_mask = Concatenate(axis=3)([x_mask,x_mask_ident_1,x_mask_ident_2,x_mask_ident_3])\n",
    "\n",
    "    x_mask = GlobalMaxPooling2D()(x_mask)\n",
    "    x_mask = BatchNormalization(name=\"final_features_344_mask\")(x_mask)\n",
    "    \n",
    "    ##################################################################################################################\n",
    "    x = concatenate([x,x_mask])\n",
    "        \n",
    "    x = Dense(64, activation='relu', name=\"final_features_64\")(x)\n",
    "    out_class = Dense(5, activation='softmax', name='out_class')(x)\n",
    "\n",
    "    model = Model(input=[inputs,inputs_mask], output=out_class)\n",
    "    \n",
    "    if load_weight_path is not None: model.load_weights(load_weight_path, by_name=False)\n",
    "\n",
    "    optimizer = SGD(lr=0.001, momentum=0.9, nesterov=True)\n",
    "    loss = {\"out_class\": \"categorical_crossentropy\"}\n",
    "    metrics={\"out_class\": [categorical_accuracy, categorical_crossentropy]}\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    model.summary(line_length=140)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5d6796-32b7-4194-a293-dee16e375174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cabade1-29f5-407e-8908-6515c5e2ec32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
